# ğŸ§  BuildBrain ML System - Complete Implementation

## Overview

BuildBrain es una plataforma GUI profesional para machine learning construida con **Flet** y **Python**, que integra:

- **25+ modelos ML pre-implementados** (scikit-learn, XGBoost, PyTorch)
- **Sistema de fÃ¡brica (Factory Pattern)** para instanciaciÃ³n de modelos
- **API unificada de entrenamiento (ModelTrainer)** para todos los tipos de modelos
- **Interfaz grÃ¡fica moderna** con diseÃ±o inspirado en Android Studio Dark
- **Soporte para GPU/CUDA** en modelos de deep learning

---

## ğŸ—ï¸ Arquitectura del Sistema

### Estructura de Carpetas

```
src/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py                 # Exporta todos los modelos
â”‚   â”‚   â”œâ”€â”€ supervised_models.py        # 10 modelos supervisados
â”‚   â”‚   â”œâ”€â”€ unsupervised_models.py      # 7 modelos no supervisados
â”‚   â”‚   â”œâ”€â”€ anomaly_detection.py        # 2 modelos de detecciÃ³n de anomalÃ­as
â”‚   â”‚   â””â”€â”€ deep_learning.py            # 5 modelos PyTorch (incluyendo ResNets)
â”‚   â”œâ”€â”€ model_factory.py                # Factory Pattern para crear modelos
â”‚   â”œâ”€â”€ model_trainer.py                # API unificada de entrenamiento
â”‚   â”œâ”€â”€ trainer.py                      # Legacy trainer
â”‚   â””â”€â”€ models.py                       # Legacy models
â”œâ”€â”€ gui/
â”‚   â”œâ”€â”€ welcome_screen.py               # Pantalla de bienvenida con grid de proyectos
â”‚   â”œâ”€â”€ new_project_wizard.py           # Wizard dinÃ¡mico (5-7 pasos segÃºn modelo)
â”‚   â”œâ”€â”€ dataset_uploader.py             # Cargador de datasets
â”‚   â”œâ”€â”€ main_window.py                  # Ventana principal
â”‚   â””â”€â”€ ... (otros componentes GUI)
â””â”€â”€ ...
```

---

## ğŸ“š Modelos Implementados

### 1. **Supervised Learning (10 modelos)**

Archivo: `src/training/models/supervised_models.py`

| Modelo | Tipo | Casos de Uso |
|--------|------|-------------|
| `LinearRegressionModel` | RegresiÃ³n | PredicciÃ³n linear simple |
| `RandomForestRegressorModel` | RegresiÃ³n | RegresiÃ³n no-linear robusta |
| `XGBoostRegressorModel` | RegresiÃ³n | RegresiÃ³n con boosting |
| `SVRModel` | RegresiÃ³n | MÃ¡quinas de soporte vectorial |
| `LogisticRegressionModel` | ClasificaciÃ³n | ClasificaciÃ³n binaria/multiclase |
| `RandomForestClassifierModel` | ClasificaciÃ³n | ClasificaciÃ³n robusta |
| `XGBoostClassifierModel` | ClasificaciÃ³n | ClasificaciÃ³n con boosting |
| `KNNModel` | ClasificaciÃ³n | K-vecinos mÃ¡s cercanos |
| `SVMModel` | ClasificaciÃ³n | MÃ¡quinas de soporte vectorial |
| `NaiveBayesModel` | ClasificaciÃ³n | ClasificaciÃ³n probabilÃ­stica |

**MÃ©tricas de evaluaciÃ³n:**
- RegresiÃ³n: MSE, RMSE, MAE, RÂ²
- ClasificaciÃ³n: Accuracy, Precision, Recall, F1 Score

### 2. **Unsupervised Learning (7 modelos)**

Archivo: `src/training/models/unsupervised_models.py`

| Modelo | Tipo | Casos de Uso |
|--------|------|-------------|
| `KMeansModel` | Clustering | AgrupaciÃ³n K-medias |
| `DBSCANModel` | Clustering | Clustering basado en densidad |
| `MeanShiftModel` | Clustering | Clustering basado en modos |
| `GaussianMixtureModel` | Clustering | Clustering probabilÃ­stico |
| `PCAModel` | Dimensionality Reduction | ReducciÃ³n a componentes principales |
| `TSNEModel` | Dimensionality Reduction | VisualizaciÃ³n t-SNE |
| `UMAPModel` | Dimensionality Reduction | ReducciÃ³n UMAP |

**MÃ©tricas de evaluaciÃ³n:**
- Silhouette Score
- Davies-Bouldin Index
- BIC/AIC (para modelos probabilÃ­sticos)
- Explained Variance (para reducciÃ³n dimensional)

### 3. **Anomaly Detection (2 modelos)**

Archivo: `src/training/models/anomaly_detection.py`

| Modelo | TÃ©cnica | Casos de Uso |
|--------|---------|-------------|
| `IsolationForestModel` | Ensemble | DetecciÃ³n de outliers con Isolation Forest |
| `OneClassSVMModel` | SVM | One-class SVM para detecciÃ³n de anomalÃ­as |

**MÃ©tricas de evaluaciÃ³n:**
- Anomaly Rate
- Contamination Score
- Decision Function Values

### 4. **Deep Learning (5 modelos con PyTorch)**

Archivo: `src/training/models/deep_learning.py`

| Modelo | Tipo | Arquitectura |
|--------|------|-------------|
| `ResNet18Model` | CNN | ResNet con 2 residual blocks |
| `ResNet34Model` | CNN | ResNet con 3-4-6-3 residual blocks |
| `ResNet50Model` | CNN | ResNet con 3-4-6-3 bottleneck blocks |
| `PyTorchCNNModel` | CNN | Red convolucional personalizada (3 capas) |
| `PyTorchMLPModel` | MLP | Red densa de 4 capas |

**CaracterÃ­sticas:**
- âœ… Soporte GPU/CUDA automÃ¡tico
- âœ… Adam optimizer
- âœ… Cross Entropy Loss
- âœ… Training history tracking
- âœ… Batch processing

---

## ğŸ”§ APIs Principales

### ModelFactory - Factory Pattern

```python
from src.training.model_factory import ModelFactory

# Crear un modelo
model = ModelFactory.create_model("RandomForestClassifier", n_estimators=100)

# Obtener categorÃ­a del modelo
category = ModelFactory.get_model_category("ResNet18")
# Output: "deep_learning"

# Obtener hiperparÃ¡metros por defecto
hyperparams = ModelFactory.get_default_hyperparameters("LogisticRegression")
# Output: {'max_iter': 200, 'C': 1.0, ...}
```

### ModelTrainer - Unified Training API

```python
from src.training.model_trainer import ModelTrainer
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Crear trainer
config = {
    "name": "my_project",
    "model_type": "LogisticRegression",
    "model_category": "supervised",
    "hyperparameters": {"max_iter": 200}
}
trainer = ModelTrainer("LogisticRegression", config)

# Entrenar modelo
trainer.train(X_train, y_train, validation_split=0.2)

# Evaluar modelo
metrics = trainer.evaluate(X_test, y_test)
print(metrics)  # {'accuracy': 0.95, 'precision': 0.94, ...}

# Hacer predicciones
predictions = trainer.predict(X_test)

# Guardar modelo
trainer.save_model("model.pkl")

# Cargar modelo
loaded_trainer = ModelTrainer.load_model("model.pkl", config)
```

---

## ğŸ¨ Interfaz de Usuario (GUI)

### Tema Dark (Android Studio Inspired)

```python
Colors = {
    "bg_primary": "#0D0D0D",      # Fondo principal
    "bg_secondary": "#1A1A1A",    # Tarjetas/Contenedores
    "border": "#2D2D2D",           # Bordes
    "accent_green": "#3DDC84",     # Botones principales
    "accent_blue": "#82B1FF",      # Botones secundarios
    "accent_orange": "#FFB74D",    # Warnings
    "accent_red": "#FF6B6B",       # Errors
    "text_primary": "#CCCCCC",     # Texto principal
    "text_secondary": "#AAAAAA",   # Texto secundario
    "text_tertiary": "#888888",    # Texto terciario
}
```

### Flujos del Wizard

El wizard es **dinÃ¡mico** y cambia los pasos segÃºn el tipo de modelo seleccionado:

#### Supervised Learning (6 pasos)
1. **Project Name** - Nombre del proyecto
2. **Task Config** - Tipo de tarea (Classification/Regression)
3. **Classes Setup** - Definir clases (para clasificaciÃ³n)
4. **Balance Dataset** - Â¿Balancear clases?
5. **Dataset Upload** - Cargar datos
6. **Training Logs** - Entrenar y ver resultados

#### Unsupervised Learning (5 pasos)
1. **Project Name** - Nombre del proyecto
2. **Model Selection** - Seleccionar modelo (KMeans, DBSCAN, etc.)
3. **Unsupervised Params** - ParÃ¡metros especÃ­ficos (n_clusters, etc.)
4. **Dataset Upload** - Cargar datos
5. **Training Logs** - Entrenar y ver resultados

#### Anomaly Detection (5 pasos)
1. **Project Name** - Nombre del proyecto
2. **Anomaly Config** - Configurar contamination %
3. **Training Params** - ParÃ¡metros de entrenamiento
4. **Dataset Upload** - Cargar datos
5. **Training Logs** - Entrenar y detectar anomalÃ­as

#### Deep Learning (7 pasos)
1. **Project Name** - Nombre del proyecto
2. **NN Type** - Tipo de red (ResNet, CNN, MLP)
3. **NN Config** - Arquitectura de la red
4. **Training Params** - Ã‰pocas, batch size, learning rate
5. **Dataset Upload** - Cargar datos
6. **Training Logs** - Entrenar con feedback visual
7. **Export Model** - Guardar modelo entrenado

---

## ğŸ’» Ejemplos de Uso

### Ejemplo 1: ClasificaciÃ³n Supervisada

```python
from src.training.model_trainer import ModelTrainer
from src.training.model_factory import ModelFactory

# Crear configuraciÃ³n
config = {
    "name": "iris_classifier",
    "model_type": "RandomForestClassifier",
    "model_category": "supervised",
    "hyperparameters": ModelFactory.get_default_hyperparameters("RandomForestClassifier")
}

# Crear trainer
trainer = ModelTrainer("RandomForestClassifier", config)

# Entrenar
trainer.train(X_train, y_train, validation_split=0.2)

# Evaluar
metrics = trainer.evaluate(X_test, y_test)
print(f"Accuracy: {metrics['accuracy']:.4f}")
print(f"F1 Score: {metrics['f1_score']:.4f}")

# Predicciones
predictions = trainer.predict(X_new)
```

### Ejemplo 2: Clustering No Supervisado

```python
# Crear trainer para KMeans
config = {
    "name": "customer_segmentation",
    "model_type": "KMeans",
    "model_category": "unsupervised",
    "hyperparameters": {"n_clusters": 3}
}

trainer = ModelTrainer("KMeans", config)

# Entrenar (sin labels)
trainer.train(X_unlabeled, None)

# Asignar clusters
clusters = trainer.predict(X_new)
print(f"Clusters asignados: {clusters}")

# Evaluar con Silhouette Score
metrics = trainer.evaluate(X_unlabeled, None)
print(f"Silhouette Score: {metrics:.4f}")
```

### Ejemplo 3: Deep Learning con ResNet

```python
import torch

# Crear trainer para ResNet50
config = {
    "name": "image_classifier",
    "model_type": "ResNet50",
    "model_category": "deep_learning",
    "hyperparameters": {
        "num_classes": 10,
        "pretrained": False
    }
}

trainer = ModelTrainer("ResNet50", config)

# Entrenar con Ã©pocas
trainer.train(
    X_train, y_train,
    validation_split=0.2,
    epochs=50,
    batch_size=32,
    learning_rate=0.001
)

# Resultados
summary = trainer.get_summary()
print(f"Training history: {summary['training_history']}")
```

---

## ğŸš€ CaracterÃ­sticas Principales

### âœ… Completado

- [x] 25+ modelos ML implementados
- [x] ResNet18, ResNet34, ResNet50 con arquitecturas reales
- [x] Factory Pattern para instanciaciÃ³n
- [x] API unificada (ModelTrainer)
- [x] Soporte GPU/CUDA automÃ¡tico
- [x] ValidaciÃ³n y preprocesamiento (StandardScaler)
- [x] EvaluaciÃ³n de modelos con mÃ©tricas reales
- [x] Persistencia (save/load con pickle)
- [x] Interfaz dinÃ¡mmica del wizard
- [x] Tema dark profesional
- [x] IntegraciÃ³n con GUI

### ğŸ”„ En Progreso

- ğŸŸ¡ HiperpÃ¡metros en tiempo real (UI â†” Model)
- ğŸŸ¡ Callbacks de progreso (entrenamiento en vivo)
- ğŸŸ¡ VisualizaciÃ³n de mÃ©tricas (grÃ¡ficos)

### â­• Por Implementar

- â­• Export modelo a ONNX
- â­• Deployment a cloud
- â­• Versioning de modelos
- â­• Cross-validation automÃ¡tica

---

## ğŸ“¦ Dependencias

```
flet>=0.21.0
pandas>=2.0.0
scikit-learn>=1.3.0
xgboost>=2.0.0
torch>=2.0.0
torchvision>=0.15.0
matplotlib>=3.7.0
plotly>=5.15.0
joblib>=1.3.0
numpy>=1.24.0
pillow>=10.0.0
imbalanced-learn>=0.11.0
onnx>=1.14.0
onnxruntime>=1.15.0
```

Instalar con:
```bash
pip install -r requirements.txt
```

---

## ğŸ¯ PrÃ³ximos Pasos

1. **VisualizaciÃ³n de MÃ©tricas**
   - GrÃ¡ficos de training loss
   - Curvas de precisiÃ³n-recall
   - Matrices de confusiÃ³n

2. **OptimizaciÃ³n AutomÃ¡tica**
   - Grid Search para hiperparÃ¡metros
   - Cross-validation automÃ¡tica

3. **ExportaciÃ³n y Deployment**
   - Export a ONNX
   - ContenedorizaciÃ³n con Docker
   - Deployment a Azure/AWS

4. **Mejoras de UX**
   - Progreso en tiempo real
   - CancelaciÃ³n de entrenamientos
   - Historial de experimentos

---

## ğŸ“ Notas TÃ©cnicas

### JerarquÃ­a de Clases

```
BaseModel (Abstract)
â”œâ”€â”€ LinearRegressionModel
â”œâ”€â”€ RandomForestRegressorModel
â”œâ”€â”€ XGBoostRegressorModel
â”œâ”€â”€ SVRModel
â”œâ”€â”€ LogisticRegressionModel
â”œâ”€â”€ RandomForestClassifierModel
â”œâ”€â”€ XGBoostClassifierModel
â”œâ”€â”€ KNNModel
â”œâ”€â”€ SVMModel
â””â”€â”€ NaiveBayesModel

BaseUnsupervisedModel (Abstract)
â”œâ”€â”€ KMeansModel
â”œâ”€â”€ DBSCANModel
â”œâ”€â”€ MeanShiftModel
â”œâ”€â”€ GaussianMixtureModel
â”œâ”€â”€ PCAModel
â”œâ”€â”€ TSNEModel
â””â”€â”€ UMAPModel

BaseAnomalyDetectionModel (Abstract)
â”œâ”€â”€ IsolationForestModel
â””â”€â”€ OneClassSVMModel

BasePyTorchModel (Abstract)
â”œâ”€â”€ ResNet18Model
â”œâ”€â”€ ResNet34Model
â”œâ”€â”€ ResNet50Model
â”œâ”€â”€ PyTorchCNNModel
â””â”€â”€ PyTorchMLPModel
```

### Patrones de DiseÃ±o Utilizados

1. **Factory Pattern** (ModelFactory)
   - CreaciÃ³n centralizada de modelos
   - Defaults automÃ¡ticos por tipo

2. **Strategy Pattern** (ModelTrainer)
   - Diferentes estrategias de entrenamiento por categorÃ­a
   - API unificada para todos

3. **Template Method** (BaseModel classes)
   - MÃ©todos comunes: fit, predict, evaluate
   - ImplementaciÃ³n especÃ­fica en subclases

---

## ğŸ› Troubleshooting

### Error: CUDA no disponible
```python
# Los modelos detectan automÃ¡ticamente GPU
# Si no hay CUDA, usan CPU
# Ver en los logs: "GPU not available, using CPU"
```

### Error: MÃ³dulo no encontrado
```bash
# Reinstalar dependencias
pip install --upgrade -r requirements.txt
```

### Error: Memoria insuficiente
```python
# Reducir batch_size en training
trainer.train(X, y, batch_size=16)
```

---

## ğŸ“„ Licencia

BuildBrain Â© 2024 - Open Source

---

## ğŸ‘¨â€ğŸ’» Autor

Developed with â¤ï¸ by GitHub Copilot
