# üöÄ BuildBrain ML System - Quick Start Guide

## Instalaci√≥n R√°pida

### 1. Clonar el Repositorio
```bash
git clone <repository-url>
cd BuildBrain
```

### 2. Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 3. Ejecutar la Aplicaci√≥n
```bash
python main.py
```

La aplicaci√≥n abrir√° una ventana con la interfaz gr√°fica de BuildBrain.

---

## üéØ Flujo R√°pido: Crear tu Primer Modelo

### Paso 1: Bienvenida
1. Ejecuta `python main.py`
2. Se abrir√° la pantalla de bienvenida con un bot√≥n **"Get Started"**

### Paso 2: Crear Proyecto
1. Click en **"Get Started"**
2. Se abrir√° el wizard din√°mico
3. **Nombre del proyecto**: ej. `iris_classifier`

### Paso 3: Seleccionar Modelo
Elige uno de los 25+ modelos disponibles:

**Supervisados (para tus datos etiquetados):**
- LogisticRegression (clasificaci√≥n)
- RandomForestClassifier (clasificaci√≥n robusta)
- LinearRegression (regresi√≥n)
- SVR (regresi√≥n no-linear)

**No Supervisados (para descubrir patrones):**
- KMeans (agrupaci√≥n)
- DBSCAN (agrupaci√≥n por densidad)
- PCA (reducci√≥n dimensional)

**Deep Learning (redes neuronales):**
- ResNet18, ResNet34, ResNet50
- PyTorchCNN (convolucional)
- PyTorchMLP (densa)

**Detecci√≥n de Anomal√≠as:**
- IsolationForest
- OneClassSVM

### Paso 4: Cargar Dataset
1. Haz click en **"Seleccionar Dataset"**
2. Selecciona tu archivo CSV/XLSX
3. El sistema autom√°ticamente:
   - Detecta features y labels
   - Preprocesa datos (normalizaci√≥n)
   - Divide en train/test

### Paso 5: Entrenar Modelo
1. Haz click en **"Crear Modelo"**
2. El sistema iniciar√° el entrenamiento
3. Ver√°s en tiempo real:
   - Progreso de entrenamiento
   - Logs de cada paso
   - M√©tricas de rendimiento

### Paso 6: Ver Resultados
Una vez completado, obtendr√°s:
- ‚úÖ Accuracy, Precision, Recall, F1 Score (si aplica)
- ‚úÖ Modelo guardado en `projects/<nombre_proyecto>/models/`
- ‚úÖ Logs en `projects/<nombre_proyecto>/logs/`

---

## üíª Ejemplo Desde C√≥digo Python

Si prefieres usar BuildBrain desde Python en lugar de la GUI:

### Clasificaci√≥n Supervisada
```python
from src.training.model_trainer import ModelTrainer
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Cargar datos
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Crear configuraci√≥n
config = {
    "name": "mi_proyecto",
    "model_type": "RandomForestClassifier",
    "model_category": "supervised",
    "hyperparameters": {
        "n_estimators": 100,
        "max_depth": 10
    }
}

# Crear trainer
trainer = ModelTrainer("RandomForestClassifier", config)

# Entrenar
trainer.train(X_train, y_train, validation_split=0.2)

# Evaluar
metrics = trainer.evaluate(X_test, y_test)
print(f"Accuracy: {metrics['accuracy']:.4f}")

# Predicciones
predictions = trainer.predict(X_test[:5])
print(f"Predicciones: {predictions}")

# Guardar modelo
trainer.save_model("models/mi_modelo.pkl")
```

### Clustering No Supervisado
```python
from src.training.model_trainer import ModelTrainer
import numpy as np

# Datos sin etiquetas
X = np.random.randn(100, 2)

config = {
    "name": "clustering",
    "model_type": "KMeans",
    "model_category": "unsupervised",
    "hyperparameters": {"n_clusters": 3}
}

trainer = ModelTrainer("KMeans", config)
trainer.train(X, None)  # None porque no hay labels

# Asignar clusters
clusters = trainer.predict(X[:10])
print(f"Clusters: {clusters}")
```

### Deep Learning (Redes Neuronales)
```python
from src.training.model_trainer import ModelTrainer
import numpy as np

# Datos para deep learning
X_train = np.random.randn(1000, 784)  # 28x28 im√°genes (flattened)
y_train = np.random.randint(0, 10, 1000)  # 10 clases

config = {
    "name": "deep_learning_model",
    "model_type": "ResNet50",
    "model_category": "deep_learning",
}

trainer = ModelTrainer("ResNet50", config)

# Entrenar con √©pocas
trainer.train(
    X_train, y_train,
    epochs=20,
    batch_size=32,
    learning_rate=0.001
)

# Ver historial de entrenamiento
summary = trainer.get_summary()
print(f"Training history: {summary['training_history']}")
```

---

## üìä Todos los Modelos Disponibles

### Supervisados (10 modelos)
```python
modelos = [
    "LinearRegression",           # Regresi√≥n lineal
    "RandomForestRegressor",      # Random Forest para regresi√≥n
    "XGBoostRegressor",          # Boosting para regresi√≥n
    "SVR",                       # Support Vector Regressor
    "LogisticRegression",        # Clasificaci√≥n log√≠stica
    "RandomForestClassifier",    # Random Forest para clasificaci√≥n
    "XGBoostClassifier",         # Boosting para clasificaci√≥n
    "KNN",                       # K-Vecinos m√°s cercanos
    "SVM",                       # Support Vector Machine
    "NaiveBayes",               # Clasificador Naive Bayes
]
```

### No Supervisados (7 modelos)
```python
modelos = [
    "KMeans",              # K-medias
    "DBSCAN",              # Clustering por densidad
    "MeanShift",           # Clustering por modos
    "GaussianMixture",     # Modelos de mezcla gaussiana
    "PCA",                 # An√°lisis de componentes principales
    "TSNE",                # t-Distributed Stochastic Neighbor Embedding
    "UMAP",                # Uniform Manifold Approximation and Projection
]
```

### Detecci√≥n de Anomal√≠as (2 modelos)
```python
modelos = [
    "IsolationForest",     # Isolation Forest
    "OneClassSVM",         # SVM de una clase
]
```

### Deep Learning (5 modelos)
```python
modelos = [
    "ResNet18",            # ResNet con 18 capas
    "ResNet34",            # ResNet con 34 capas
    "ResNet50",            # ResNet con 50 capas (bottleneck)
    "PyTorchCNN",          # Red convolucional personalizada
    "PyTorchMLP",          # Red densa multicapa
]
```

---

## üß™ Ejecutar Tests

Para validar que todo funciona correctamente:

```bash
python test_ml_system.py
```

Esto ejecutar√° tests de:
- ‚úÖ Instanciaci√≥n de todos los modelos
- ‚úÖ Entrenamiento de cada modelo
- ‚úÖ Evaluaci√≥n y m√©tricas
- ‚úÖ Persistencia (save/load)
- ‚úÖ Predicciones

---

## üìÅ Estructura de Archivos Despu√©s de Crear un Proyecto

```
BuildBrain/
‚îú‚îÄ‚îÄ projects/
‚îÇ   ‚îî‚îÄ‚îÄ mi_proyecto/
‚îÇ       ‚îú‚îÄ‚îÄ project_config.json      # Configuraci√≥n del proyecto
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ trained_model.pkl    # Modelo entrenado
‚îÇ       ‚îú‚îÄ‚îÄ data/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train.csv           # Datos de entrenamiento
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ test.csv            # Datos de prueba
‚îÇ       ‚îî‚îÄ‚îÄ logs/
‚îÇ           ‚îî‚îÄ‚îÄ training_log.txt    # Log del entrenamiento
‚îú‚îÄ‚îÄ models/                          # Modelos globales
‚îú‚îÄ‚îÄ logs/                            # Logs globales
‚îî‚îÄ‚îÄ ...
```

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar Hiperpar√°metros

```python
from src.training.model_factory import ModelFactory

# Obtener hiperpar√°metros por defecto
defaults = ModelFactory.get_default_hyperparameters("RandomForestClassifier")
print(defaults)  
# Output: {'n_estimators': 100, 'max_depth': None, 'random_state': 42}

# Usar hiperpar√°metros personalizados
config = {
    "name": "custom_params",
    "model_type": "RandomForestClassifier",
    "model_category": "supervised",
    "hyperparameters": {
        "n_estimators": 200,  # M√°s √°rboles
        "max_depth": 15,      # √Årboles m√°s profundos
        "random_state": 42
    }
}

trainer = ModelTrainer("RandomForestClassifier", config)
```

### Usar GPU/CUDA

Los modelos de PyTorch detectan autom√°ticamente GPU:

```python
import torch

# Verificar si CUDA est√° disponible
print(f"GPU Available: {torch.cuda.is_available()}")

# Los modelos la usar√°n autom√°ticamente
trainer = ModelTrainer("ResNet50", config)
# Se ver√° un log: "GPU available, using CUDA"
```

---

## üêõ Troubleshooting

### Error: "ModuleNotFoundError: No module named 'torch'"
```bash
# Instalar dependencias nuevamente
pip install --upgrade -r requirements.txt
```

### Error: "CUDA out of memory"
```python
# Reducir batch size
trainer.train(X, y, batch_size=16)  # En lugar de 32
```

### Error: "No se puede cargar el dataset"
```python
# Asegurate que el archivo es CSV o Excel
# Formatos soportados: .csv, .xlsx, .json, .parquet

# O cargalo manualmente
import pandas as pd
df = pd.read_csv("mi_datos.csv")
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
```

---

## üìö Documentaci√≥n Completa

Para documentaci√≥n m√°s detallada, ver:
- `ML_SYSTEM_DOCUMENTATION.md` - Documentaci√≥n t√©cnica completa
- `example_usage.py` - Ejemplos de c√≥digo
- `test_ml_system.py` - Tests de integraci√≥n

---

## üéì Pasos Recomendados

**Para principiantes:**
1. Ejecuta `python main.py`
2. Crea un proyecto con LogisticRegression
3. Carga el dataset Iris (viene en scikit-learn)
4. Observa c√≥mo funciona el proceso

**Para usuarios intermedios:**
1. Experimenta con diferentes modelos
2. Ajusta hiperpar√°metros
3. Compara resultados entre modelos

**Para usuarios avanzados:**
1. Modifica el c√≥digo de los modelos
2. A√±ade nuevas m√©tricas
3. Crea modelos personalizados

---

## üöÄ Pr√≥ximos Pasos

- Exportar modelos a ONNX
- Hacer deploy a Azure/AWS
- Crear pipelines de machine learning
- Automl con b√∫squeda de hiperpar√°metros
- Explicabilidad con SHAP

---

¬°Ahora est√°s listo para comenzar! üéâ

Cualquier pregunta o problema, revisa los logs en `logs/` o ejecuta `test_ml_system.py`.
